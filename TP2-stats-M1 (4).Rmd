---
title: "Compte-rendu Statistiques -- TP2"
subtitle: Analyse en composantes principales et apprentissage
author: Amine Elachar et abdallah elmaazouzi
output:
  word_document: default
  pdf_document:
    number_sections: yes
---


\tableofcontents


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Exercices

## Les iris de Fischer

On considère le fichier `iris.csv` sur Celene répertoriant 150 individus fleurs d'iris. On donne la description suivante des colonnes:

|Colonne|Description|Value|
|---------------|-------------------|-----------------------|
|`sepal_length`|Longueur des sépales|Int|
|`sepal_width`|Largeur des sépales|Int|
|`petal_length`|Longueur des pétales|Int|
|`petal_width`|Largeur des pétales|Int|
|`species`|Espèce d'iris|\{Versicolor, Virginica, Setosa\}|


![Les iris de Fischer](irises.png){width=100%}

1. Statistiques descriptives
> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `iris`. Votre analyse^[Vous pourrez vous aider la fonction `chart.Correlation` de la librairie `PerformanceAnalytics`. ] devra contenir notamment:

> > - Distribution de chaque variable puis analyses synthétiques agrégées par espèce.

> > - Corrélation entre les variables.

Premièrement nous voulons étudier combien de ligne et colonnes on a dans la source de données iris: (150 ligne et 5 colonnes)

```{r}

iris <- read.csv("C:/Users/incognito/Downloads/iris.csv", sep=";")
dim(iris)
```
afin d'étudier les statistics de notre source de données(min max moyenne et écart type: 
```{r}
summary(iris)
```
```{r}
# To make a visualisation in R, we can use the core plotting functions of R.
 # A histogram shows the underlying frequency distribution. We use the function 'hist()'
hist(iris[, 'Sepal.Width'], main= 'Histogram of sepal width for all flowers', xlab='Width (cm)')


```

```{r}

iris <- read.csv("C:/Users/incognito/Downloads/iris.csv", sep=";")
library(RColorBrewer)
boxplot(iris[0:4],
names(iris)[0:4],
main = "Repartition des differentes statistiques des Sepal",
col = brewer.pal(n = 4, name = "Set1"))

variables<-iris[0:4]

```
-> La boxplot indique principalement les informations des quantiles Q1 et Q3 ainsi que la médiane pour toutes les variables choisies

> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ? 

```{r, echo = FALSE, results='hide', message=FALSE}
library(PerformanceAnalytics)
chart.Correlation(variables,TRUE)
```

-> Ce graphique représente la corrélation entre les variables. Comme on peut voir les variables Sepal.length et Sepal.width sont les variables les moins corréles entre eux.

> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ? 

Les variables qui semblent les plus pertinentes pour l'acp sont Sepal.length et Sepal.width


2.  Calculer les valeurs propres de la matrice des données `iris`. Combien d'axes proposez vous de retenir pour l'ACP ? Détaillez votre réponse. 


```{r}
library("FactoMineR")
iris.pca <- PCA(variables, graph = FALSE)
library("factoextra")
eig.val <- get_eigenvalue(iris.pca)
round(eig.val,2)
```
afin d'observer le graphique des valeurs propres on a executé la commande suivante: 

```{r}
fviz_eig(iris.pca, addlabels = TRUE)

```
Remarque: sur ce graphique on peut remarquer que la première dimension explique une grande partie de l'information de notre nuage de points de 73%

En terme de variance cumulée , les deux premières dimensions expliquent 95.9% de l'information de notre jeu de données ce qui est exellent 


3. Analyse des variables
> (a) Dresser le cercle des corrélations de l'ACP. Commentez la qualité de représentation et la contribution de chaque variable quant aux axes retenus. 

Le cercle des corrélations est un cercle, de rayon 1 où l’axe des abscisses représente le premier axe factoriel selon
~v1 et l’axe des ordonnées le second axe.

À l’intérieur du cercle, des flèches partent du centre. Elles sont plus ou moins grandes, et peuvent aller jusqu’à
toucher le cercle, sans jamais le dépasser.


```{r}
fviz_pca_var(iris.pca, col.var = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE )

```

> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels. 


On peut voir que toutes les variables sont très corrélées à l'axe factoriel engendré par $\vec{v_1}$. Toutes les flèches dépassent une valeur projetée de 0.75 sur `Dim1`.

Afin de voir plus préciseamment les coordonnées précises des composantes princiipales :

```{r}
round(get_pca_var(iris.pca)$coord, 2)
```



4. Analyse des individus

> (a) Présenter la projection des indivus dans le plan factoriel. Vous colorerez dans un premier temps les points en fonction de l'espèce d'iris. 
> (b) Colorer les individus en fonction de leur contribution aux axes factoriels. Que remarquez-vous ? Pouvez l'expliquer ? 

```{r}
library(RColorBrewer)
fviz_pca_ind(iris.pca, axes = c(1,2), geom.ind = "point", col.ind = iris[,5])
```

Cette projection vient confirmer notre analyse précédente du cercle des corrélations

On retrouve bien un clivage des espèces selon l’axe Dim1, entre la gauche et la droite.

(c) Commenter la qualité de représentation des individus.


5. Apprentissage statistique
L’option addEllipses=TRUE de la fonction fviz_pca_ind permet de dessiner l’ellipse de confiance
(covariance ellipse error) à 95%.

```{r}
library(RColorBrewer)
fviz_pca_ind(iris.pca, axes = c(1,2), addEllipses = TRUE ,geom.ind = "point", col.ind = iris[,5])
```


(b) Proposer un algorithme permettant de classifier automatiquement une nouvelle iris inconnue et ainsi déterminer son espèce. Vous évoquerez les limites de votre approche et possibilités pour
pallier à ces effets.

L'algorthme qu'on peut proposer c'est par rapport au sepal_width et sepal_length comme on peut voir on peut par exemple déduire à  partir d'une espèce qui le sepal_width:
si sepal_width <=-1 :
      alors c'est une Stosa 
Si -1<Sepal_width<1:
      alors c'est une versicolor
Si Sepal_width>1:
      alors c'est une virginica
    
> 5. Reprendre l'analyse du jeu de données `iris` mais en effectuant ici une ACP **non réduite**. On appliquera pour ça l'option `scale = FALSE`lors de l'exécution de la fonction `PCA`.       

```{r}
library("FactoMineR")
iris_non_reduite.pca <- PCA(variables, graph = FALSE, scale=FALSE)
library("factoextra")
eig_non_reduite.val <- get_eigenvalue(iris_non_reduite.pca)
round(eig_non_reduite.val,2)
```

Comme on peut remarquer que pour la dimension 1 explique 92.46 notre jeux de données plus que l'acp.

afin d'observer le graphique des valeurs propres on a executé la commande suivante: 

```{r}
fviz_eig(iris_non_reduite.pca, addlabels = TRUE)
```

Remarque: sur ce graphique on peut remarquer que la première dimension explique une grande partie de l'information de notre nuage de points de 97.77%

En terme de variance cumulée , les deux premières dimensions expliquent 95.9% de l'information de notre jeu de données ce qui est exellent 

> 3. Analyse des variables:

```{r}
fviz_pca_var(iris_non_reduite.pca, col.var = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE )

```


> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels. 


On peut voir que toutes les variables sont très corrélées à l'axe factoriel engendré par $\vec{v_1}$. Toutes les flèches dépassent une valeur projetée de 0.75 sur `Dim1`.

Afin de voir plus préciseamment les coordonnées précises des composantes princiipales :

```{r}
round(get_pca_var(iris_non_reduite.pca)$coord, 2)
```



4. Analyse des individus

> (a) Présenter la projection des indivus dans le plan factoriel. Vous colorerez dans un premier temps les points en fonction de l'espèce d'iris. 
> (b) Colorer les individus en fonction de leur contribution aux axes factoriels. Que remarquez-vous ? Pouvez l'expliquer ? 

```{r}
library(RColorBrewer)
fviz_pca_ind(iris_non_reduite.pca, axes = c(1,2), geom.ind = "point", col.ind = iris[,5])
```

Cette projection vient confirmer notre analyse précédente du cercle des corrélations

On retrouve bien un clivage des espèces selon l’axe Dim1, entre la gauche et la droite.

(c) Commenter la qualité de représentation des individus.


5. Apprentissage statistique
L’option addEllipses=TRUE de la fonction fviz_pca_ind permet de dessiner l’ellipse de confiance
(covariance ellipse error) à 95%.

```{r}
library(RColorBrewer)
fviz_pca_ind(iris_non_reduite.pca, axes = c(1,2), addEllipses = TRUE ,geom.ind = "point", col.ind = iris[,5])
```


> Que remarquez vous ? Quelle méthode semble finalement donner les meilleurs résultats ici ? Expliquer ces résultats. 


à terminer

## Sommeil des mammifères

On considère le fichier `sleep.csv` sur Celene répertoriant les données de 70 espèces de mammifères concernant leur sommeil et quelques autres caractéristiques. On donne la description suivante des colonnes:

|Colonne|Description|Value|
|---------------|-----------------------------------|----------------|
|`name`|Nom français vernaculaire de l'animal|String|
|`genus`|Genre, subdivion de la classification biologique|String|
|`vore`|Régime alimentaire de l'animal|String|
|`order`|Ordre, subdivion de la classification biologique|String|
|`sleep_total`|Durée (en h) de sommeil sur une journée|Double|
|`sleep_rem`|Durée (en h) de sommeil paradoxal|Double|
|`awake`|Durée (en h) où l'animal est éveillé|Double|
|`brain_wt`|Masse (en kg) moyenne du cerveau de l'animal|Double|
|`body_wt`|Masse (en kg) totale moyenne de l'animal|Double|
|`brain_body_ratio`|Ratio masse cerveau, masse totale $\frac{\mathtt{brain\_wt}}{\mathtt{body\_wt}}$|Double|
|`gest_day`|Période de gestation moyenne de l'animal|Int|
      
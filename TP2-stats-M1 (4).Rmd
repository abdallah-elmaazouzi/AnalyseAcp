---
title: "Compte-rendu Statistiques -- TP2"
subtitle: Analyse en composantes principales et apprentissage
autor: Amine Elachar 
output:
  word_document: default
  pdf_document:
    number_sections: yes
---


\tableofcontents


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Exercices

## Les iris de Fischer

On considère le fichier `iris.csv` sur Celene répertoriant 150 individus fleurs d'iris. On donne la description suivante des colonnes:

|Colonne|Description|Value|
|---------------|-------------------|-----------------------|
|`sepal_length`|Longueur des sépales|Int|
|`sepal_width`|Largeur des sépales|Int|
|`petal_length`|Longueur des pétales|Int|
|`petal_width`|Largeur des pétales|Int|
|`species`|Espèce d'iris|\{Versicolor, Virginica, Setosa\}|


![Les iris de Fischer](irises.png){width=100%}

1. Statistiques descriptives
> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `iris`. Votre analyse^[Vous pourrez vous aider la fonction `chart.Correlation` de la librairie `PerformanceAnalytics`. ] devra contenir notamment:

> > - Distribution de chaque variable puis analyses synthétiques agrégées par espèce.

> > - Corrélation entre les variables.

```{r}
iris <- read.csv("C:/Users/incognito/Downloads/iris.csv", sep=";")
library(RColorBrewer)
boxplot(iris[0:4],
names(iris)[0:4],
main = "Repartition des differentes statistiques des Sepal",
col = brewer.pal(n = 4, name = "Set1"))

variables<-iris[0:4]

```
-> La boxplot indique principalement les informations des quantiles Q1 et Q3 ainsi que la médiane pour toutes les variables choisies

> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ? 

```{r}
library(PerformanceAnalytics)
chart.Correlation(variables,TRUE)
```

-> Ce graphique représente la corrélation entre les variables. Comme on peut voir les variables Sepal.length et Sepal.width sont les variables les moins corréles entre eux.

> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ? 

Les variables qui semblent les plus pertinentes pour l'acp sont Sepal.length et Sepal.width


2.  Calculer les valeurs propres de la matrice des données `iris`. Combien d'axes proposez vous de retenir pour l'ACP ? Détaillez votre réponse. 

```{r}
library("FactoMineR")
iris.pca <- PCA(variables, graph = FALSE)
library("factoextra")
eig.val <- get_eigenvalue(iris.pca)
round(eig.val,2)
```
afin d'observer le graphique des valeurs propres on a executé la commande suivante: 

```{r}
fviz_eig(iris.pca, addlabels = TRUE)

```
Remarque: sur ce graphique on peut remarquer que la première dimension explique une grande partie de l'information de notre nuage de points de 73%

En terme de variance cumulée , les deux premières dimensions expliquent 95.9% de l'information de notre jeu de données ce qui est exellent 


3. Analyse des variables
> (a) Dresser le cercle des corrélations de l'ACP. Commentez la qualité de représentation et la contribution de chaque variable quant aux axes retenus. 

Le cercle des corrélations est un cercle, de rayon 1 où l’axe des abscisses représente le premier axe factoriel selon
~v1 et l’axe des ordonnées le second axe.

À l’intérieur du cercle, des flèches partent du centre. Elles sont plus ou moins grandes, et peuvent aller jusqu’à
toucher le cercle, sans jamais le dépasser.


```{r}
fviz_pca_var(iris.pca, repel = TRUE)

```

> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels. 










> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `mnist`. Votre analyse devra contenir notamment:

> >- Nombre de caractères de chaque classe.

> >- Des premiers indicateurs sur la proportion de gris par pixel, puis agrégé par classe de caractère. 

> (b) Sur la base de ces analyses, certaines zones de l'image vous semblent t-elles plus pertinentes pour l'analyse ? Lesquelles ? Pourquoi ? 

2. Classification par l'algorithme des $k$ plus proches voisins (kNN). 

> L'algorithme des $k$ proches voisins ($k$-Nearest Neightbors) est une méthode de prédiction qui, pour une base de données d'apprentissage, cherche à déterminer la classe d'une donnée inconnue. 

> L'idée générale de cet algorithme est très simple. Pour une nouvelle donnée d'entrée $x$, on évalue sa distance à toutes les autres données connues de notre base d'apprentissage $\mathbf{X}$. 

> On rappelle que la distance euclidienne entre deux éléments $x,y\in \mathbb{R}^p$ est définie telle que:

$$\left\Vert x-y\right\Vert = \sqrt{\sum_{i=1}^p (x_i-y_i)^2}$$

> On retient ensuite uniquement les $k$ voisins $\mathbf{X_i}$ les plus proches de $x$. On regarde alors les classes $\mathbf{Y_i}$ de ces données $\mathbf{X_i}$, puis on prédit la classe la plus présente. Par défaut on utilisera $k=1$.

> (a) En assumant que $\mathbf{X}$ est doté de $n$ individus définis dans un espace de dimension $p$. Quelle est la complexité de l'algorithme des $k$-Nearest Neightbors pour $k = 1$. 

> (b) Diviser le jeu de données `mnist` en deux ensembles : 

> > - Un ensemble d'apprentissage (train set) qui contiendra 80% du jeu initial. 

> > - Un ensemble test (test set) qui contiendra le reste des données. 

> On veillera à conserver les labels des deux ensembles dans un vecteur à part. 

> (c) La commande `knn` du package `class` permet de réaliser une classification à l'aide de l'algorithme des $k$-Nearest Neightbors:

> >```{r, eval = FALSE}
> > library(class)
> > 
> > knn(X_train, X_test, cl = Y_train_label, k = nb_neightbors)
```

> > Appliquer l'algorithme kNN (avec $k=1$) sur votre ensemble d'apprentissage et de test. On veillera à sauvegarder le résultat de la fonction dans une variable `prediction`:

> > > `prediction <- knn(...)`

> > Donner le temps d'exécution de l'algorithme.

> (d) La commande `table(prediction, Y_test_label)` permet de dresser la _matrice de confusion_ $C$ de la classification effectuée. Le nombre $c_{ij}$ représente le nombre d'éléments de la classe $i$ classifiés en tant que $j$. 

> > Quel est le pourcentage de caractères manuscrits de l’ensemble de test qui ont été mal classés ? Cet algorithme vous semble t-il efficace ? Quel critique peut-on lui faire ?

> (e) Pour chaque classe, identifier un exemple de caractère mal classé par l'algorithme. Vous illustrerez ces caractères à l'aide de la fonction `img` donnée plus haut et ferez figurer la classe prédite et réelle des caractères. 

3. Prétraitement-compression des données par ACP

> (a) Effectuer une ACP du jeu `mnist` et analyser la série des valeurs propres. Combien de composantes doivent être conservées pour avoir plus de 95% de l’inertie. 

> (b) Appliquer à nouveau l'algorithme kNN mais ici vous utiliserez comme jeu initial la projection via ACP réalisée à la question précédente. Que constatez-vous ? 

> (c) Dresser la nouvelle matrice de confusion à l'issu de la classification précédente. Comparer ces résultats avec la matrice de la question 2. (d). Que peut-on dire ? 
